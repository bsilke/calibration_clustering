{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd18367",
   "metadata": {},
   "source": [
    "# Algorithm Decision Tree for Clustering Analysis\n",
    "\n",
    "This notebook provides a systematic, reproducible framework for selecting clustering algorithms based on dataset characteristics, domain requirements, and computational constraints.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Decision trees provide structured frameworks for algorithm selection that:\n",
    "- Combine multiple factors systematically\n",
    "- Guide through key decision points\n",
    "- Document rationale for stakeholder review\n",
    "- Ensure reproducible selection process\n",
    "\n",
    "## Decision Tree Structure\n",
    "\n",
    "The algorithm selection process follows four levels:\n",
    "\n",
    "1. **Data Type Assessment** ‚Äî Categorical vs numerical data\n",
    "2. **Sample Size Assessment** ‚Äî Computational feasibility\n",
    "3. **Domain Requirements** ‚Äî Application-specific needs\n",
    "4. **Special Requirements** ‚Äî Outliers, hierarchy, interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34e7eb9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6403a5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Any, Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4214a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Building Energy Clustering Flowchart\n",
    "\n",
    "The following flowchart provides a visual guide for selecting clustering algorithms specifically for building energy benchmarking applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adaa2285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "    ‚ïë           BUILDING ENERGY CLUSTERING ALGORITHM FLOWCHART                  ‚ïë\n",
      "    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "\n",
      "    START: Building Energy Benchmarking Analysis\n",
      "    ‚îÇ\n",
      "    ‚îú‚îÄ‚îÄ‚îÄ Q1: Does the dataset contain categorical variables?\n",
      "    ‚îÇ    ‚îÇ   (e.g., building type, region, meter type)\n",
      "    ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ YES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ RECOMMENDATION: K-Prototypes               ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ                                            ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Handles mixed numerical/categorical data ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Produces interpretable cluster centroids ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Suitable for peer group identification   ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
      "    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ NO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "    ‚îÇ                                                           ‚îÇ\n",
      "    ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
      "    ‚îÇ         ‚îÇ Continue to Q2                              ‚îÇ   ‚îÇ\n",
      "    ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
      "    ‚îÇ                                                           ‚îÇ\n",
      "    ‚îú‚îÄ‚îÄ‚îÄ Q2: Is outlier/anomaly detection a primary goal?       ‚îÇ\n",
      "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
      "    ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ YES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ RECOMMENDATION: DBSCAN                     ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ                                            ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Explicitly identifies outliers as noise  ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Does not force all buildings into groups ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Good for finding anomalous performers    ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
      "    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ NO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "    ‚îÇ                                                           ‚îÇ\n",
      "    ‚îú‚îÄ‚îÄ‚îÄ Q3: Is dataset size > 50,000 buildings?                ‚îÇ\n",
      "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
      "    ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ YES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ RECOMMENDATION: Mini-batch K-means         ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ                                            ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Computationally efficient for large data ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Processes data in manageable batches     ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Scalable to millions of buildings        ‚îÇ    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
      "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
      "    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ NO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "    ‚îÇ                                                           ‚îÇ\n",
      "    ‚îî‚îÄ‚îÄ‚îÄ DEFAULT                                                ‚îÇ\n",
      "         ‚îÇ                                                      ‚îÇ\n",
      "         ‚ñº                                                      ‚îÇ\n",
      "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
      "    ‚îÇ RECOMMENDATION: K-means                                ‚îÇ  ‚îÇ\n",
      "    ‚îÇ                                                        ‚îÇ  ‚îÇ\n",
      "    ‚îÇ ‚Ä¢ Well-suited for balanced peer groups                 ‚îÇ  ‚îÇ\n",
      "    ‚îÇ ‚Ä¢ Produces interpretable cluster centroids             ‚îÇ  ‚îÇ\n",
      "    ‚îÇ ‚Ä¢ Efficient and well-understood                        ‚îÇ  ‚îÇ\n",
      "    ‚îÇ ‚Ä¢ Standard choice for energy benchmarking              ‚îÇ  ‚îÇ\n",
      "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
      "                                                                ‚îÇ\n",
      "    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "\n",
      "    VALIDATION REQUIREMENTS (All Algorithms):\n",
      "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "    ‚Ä¢ Bootstrap stability assessment (100-200 resamples)\n",
      "    ‚Ä¢ Silhouette score analysis\n",
      "    ‚Ä¢ Within-cluster variance evaluation\n",
      "    ‚Ä¢ Domain expert review of cluster profiles\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def create_building_energy_flowchart() -> str:\n",
    "    \"\"\"Create a building energy-specific decision flowchart.\"\"\"\n",
    "    \n",
    "    flowchart = \"\"\"\n",
    "    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "    ‚ïë           BUILDING ENERGY CLUSTERING ALGORITHM FLOWCHART                  ‚ïë\n",
    "    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "    \n",
    "    START: Building Energy Benchmarking Analysis\n",
    "    ‚îÇ\n",
    "    ‚îú‚îÄ‚îÄ‚îÄ Q1: Does the dataset contain categorical variables?\n",
    "    ‚îÇ    ‚îÇ   (e.g., building type, region, meter type)\n",
    "    ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ YES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ RECOMMENDATION: K-Prototypes               ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ                                            ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Handles mixed numerical/categorical data ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Produces interpretable cluster centroids ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Suitable for peer group identification   ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
    "    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ NO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "    ‚îÇ                                                           ‚îÇ\n",
    "    ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "    ‚îÇ         ‚îÇ Continue to Q2                              ‚îÇ   ‚îÇ\n",
    "    ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "    ‚îÇ                                                           ‚îÇ\n",
    "    ‚îú‚îÄ‚îÄ‚îÄ Q2: Is outlier/anomaly detection a primary goal?       ‚îÇ\n",
    "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
    "    ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ YES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ RECOMMENDATION: DBSCAN                     ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ                                            ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Explicitly identifies outliers as noise  ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Does not force all buildings into groups ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Good for finding anomalous performers    ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
    "    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ NO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "    ‚îÇ                                                           ‚îÇ\n",
    "    ‚îú‚îÄ‚îÄ‚îÄ Q3: Is dataset size > 50,000 buildings?                ‚îÇ\n",
    "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
    "    ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ YES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ RECOMMENDATION: Mini-batch K-means         ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ                                            ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Computationally efficient for large data ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Processes data in manageable batches     ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îÇ ‚Ä¢ Scalable to millions of buildings        ‚îÇ    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
    "    ‚îÇ    ‚îÇ                                                      ‚îÇ\n",
    "    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ NO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "    ‚îÇ                                                           ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ DEFAULT                                                ‚îÇ\n",
    "         ‚îÇ                                                      ‚îÇ\n",
    "         ‚ñº                                                      ‚îÇ\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "    ‚îÇ RECOMMENDATION: K-means                                ‚îÇ  ‚îÇ\n",
    "    ‚îÇ                                                        ‚îÇ  ‚îÇ\n",
    "    ‚îÇ ‚Ä¢ Well-suited for balanced peer groups                 ‚îÇ  ‚îÇ\n",
    "    ‚îÇ ‚Ä¢ Produces interpretable cluster centroids             ‚îÇ  ‚îÇ\n",
    "    ‚îÇ ‚Ä¢ Efficient and well-understood                        ‚îÇ  ‚îÇ\n",
    "    ‚îÇ ‚Ä¢ Standard choice for energy benchmarking              ‚îÇ  ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "                                                                ‚îÇ\n",
    "    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "    \n",
    "    VALIDATION REQUIREMENTS (All Algorithms):\n",
    "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    ‚Ä¢ Bootstrap stability assessment (100-200 resamples)\n",
    "    ‚Ä¢ Silhouette score analysis\n",
    "    ‚Ä¢ Within-cluster variance evaluation\n",
    "    ‚Ä¢ Domain expert review of cluster profiles\n",
    "    \"\"\"\n",
    "    \n",
    "    return flowchart\n",
    "\n",
    "# Display the flowchart\n",
    "print(create_building_energy_flowchart())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e340619",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Algorithm Decision Tree Function\n",
    "\n",
    "The following function implements the systematic decision tree for algorithm selection. It evaluates dataset characteristics, domain requirements, and computational constraints to provide a reasoned recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9bede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_decision_tree(\n",
    "    data_characteristics: Dict[str, Any],\n",
    "    domain_requirements: Dict[str, Any],\n",
    "    computational_constraints: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Interactive algorithm decision tree for clustering algorithm selection.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_characteristics : dict\n",
    "        - n_samples: int, number of samples\n",
    "        - n_features: int, number of features\n",
    "        - has_categorical: bool, whether data contains categorical variables\n",
    "        - has_missing: bool, whether data contains missing values\n",
    "        - outlier_proportion: float, estimated proportion of outliers (0-1)\n",
    "        \n",
    "    domain_requirements : dict\n",
    "        - domain: str, domain type (e.g., 'building_energy', 'demographics')\n",
    "        - outlier_detection: bool, whether outlier detection is needed\n",
    "        - hierarchy: bool, whether hierarchical structure is needed\n",
    "        - peer_groups: bool, whether peer group identification is the goal\n",
    "        - interpretability: str, level needed ('high', 'medium', 'low')\n",
    "        \n",
    "    computational_constraints : dict\n",
    "        - time_minutes: int, maximum time allowed for clustering\n",
    "        - memory_gb: float, available memory in GB\n",
    "        - need_reproducibility: bool, whether reproducibility is required\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict with recommendation, alternatives, decision_path, confidence, rationale\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"ALGORITHM DECISION TREE FOR CLUSTERING\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Extract characteristics\n",
    "    n_samples = data_characteristics.get('n_samples', 0)\n",
    "    n_features = data_characteristics.get('n_features', 0)\n",
    "    has_categorical = data_characteristics.get('has_categorical', False)\n",
    "    has_missing = data_characteristics.get('has_missing', False)\n",
    "    outlier_proportion = data_characteristics.get('outlier_proportion', 0.0)\n",
    "    \n",
    "    domain = domain_requirements.get('domain', 'general')\n",
    "    needs_outliers = domain_requirements.get('outlier_detection', False)\n",
    "    needs_hierarchy = domain_requirements.get('hierarchy', False)\n",
    "    needs_peer_groups = domain_requirements.get('peer_groups', False)\n",
    "    interpretability = domain_requirements.get('interpretability', 'medium')\n",
    "    \n",
    "    time_limit = computational_constraints.get('time_minutes', 60)\n",
    "    \n",
    "    # Decision path tracking\n",
    "    decisions = []\n",
    "    alternatives = []\n",
    "    \n",
    "    # =========================================================================\n",
    "    # LEVEL 1: Data Type Assessment\n",
    "    # =========================================================================\n",
    "    print(\"\\nüìä LEVEL 1: Data Type Assessment\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if has_categorical:\n",
    "        type_decision = \"Mixed data types detected ‚Üí K-Prototypes or Gower distance required\"\n",
    "        decisions.append((\"Data Type\", type_decision))\n",
    "        mixed_data = True\n",
    "    else:\n",
    "        type_decision = \"Numerical data only ‚Üí Standard distance metrics applicable\"\n",
    "        decisions.append((\"Data Type\", type_decision))\n",
    "        mixed_data = False\n",
    "    print(f\"  ‚Üí {type_decision}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # LEVEL 2: Sample Size Assessment\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüìè LEVEL 2: Sample Size Assessment (n={n_samples:,})\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if n_samples < 500:\n",
    "        size_decision = \"Small dataset (<500) ‚Üí All algorithms feasible\"\n",
    "        size_constraint = None\n",
    "    elif n_samples < 5000:\n",
    "        size_decision = \"Medium dataset (500-5,000) ‚Üí Most algorithms feasible\"\n",
    "        size_constraint = None\n",
    "    elif n_samples < 50000:\n",
    "        size_decision = \"Large dataset (5,000-50,000) ‚Üí K-means/K-Prototypes preferred\"\n",
    "        size_constraint = 'large'\n",
    "    else:\n",
    "        size_decision = \"Very large dataset (>50,000) ‚Üí Scalable algorithms only\"\n",
    "        size_constraint = 'very_large'\n",
    "    \n",
    "    decisions.append((\"Sample Size\", size_decision))\n",
    "    print(f\"  ‚Üí {size_decision}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # LEVEL 3: Domain-Specific Requirements\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüè¢ LEVEL 3: Domain Requirements (domain={domain})\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if domain == 'building_energy':\n",
    "        domain_decision = \"Building energy benchmarking ‚Üí Peer group identification priority\"\n",
    "        decisions.append((\"Domain\", domain_decision))\n",
    "        print(f\"  ‚Üí {domain_decision}\")\n",
    "        \n",
    "        if needs_peer_groups:\n",
    "            peer_decision = \"Peer group identification needed ‚Üí Centroid-based clustering preferred\"\n",
    "            decisions.append((\"Peer Groups\", peer_decision))\n",
    "            print(f\"  ‚Üí {peer_decision}\")\n",
    "    \n",
    "    elif domain == 'environmental_justice':\n",
    "        domain_decision = \"Environmental justice ‚Üí Irregular cluster shapes expected\"\n",
    "        decisions.append((\"Domain\", domain_decision))\n",
    "        print(f\"  ‚Üí {domain_decision}\")\n",
    "    \n",
    "    else:\n",
    "        domain_decision = \"General domain ‚Üí No specific algorithm preference\"\n",
    "        decisions.append((\"Domain\", domain_decision))\n",
    "        print(f\"  ‚Üí {domain_decision}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # LEVEL 4: Special Requirements\n",
    "    # =========================================================================\n",
    "    print(f\"\\n‚öôÔ∏è LEVEL 4: Special Requirements\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if needs_outliers:\n",
    "        outlier_decision = \"Outlier detection needed ‚Üí DBSCAN advantageous\"\n",
    "        decisions.append((\"Outliers\", outlier_decision))\n",
    "        print(f\"  ‚Üí {outlier_decision}\")\n",
    "    \n",
    "    if needs_hierarchy:\n",
    "        hierarchy_decision = \"Hierarchical structure needed ‚Üí Hierarchical clustering advantageous\"\n",
    "        decisions.append((\"Hierarchy\", hierarchy_decision))\n",
    "        print(f\"  ‚Üí {hierarchy_decision}\")\n",
    "    \n",
    "    if interpretability == 'high':\n",
    "        interp_decision = \"High interpretability needed ‚Üí Centroid-based methods preferred\"\n",
    "        decisions.append((\"Interpretability\", interp_decision))\n",
    "        print(f\"  ‚Üí {interp_decision}\")\n",
    "    \n",
    "    if outlier_proportion > 0.10:\n",
    "        robust_decision = f\"High outlier proportion ({outlier_proportion:.1%}) ‚Üí Robust methods needed\"\n",
    "        decisions.append((\"Robustness\", robust_decision))\n",
    "        print(f\"  ‚Üí {robust_decision}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # FINAL RECOMMENDATION\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüéØ FINAL RECOMMENDATION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Decision logic\n",
    "    if mixed_data:\n",
    "        if size_constraint == 'very_large':\n",
    "            final_recommendation = \"Mini-batch K-Prototypes or Feature Engineering + K-means\"\n",
    "            alternatives = [\"Encode categoricals + K-means\", \"Sample data + K-Prototypes\"]\n",
    "            confidence = \"Medium\"\n",
    "        else:\n",
    "            final_recommendation = \"K-Prototypes\"\n",
    "            alternatives = [\"Gower distance + Hierarchical\", \"Encode categoricals + K-means\"]\n",
    "            confidence = \"High\"\n",
    "        \n",
    "        rationale = (\n",
    "            \"K-Prototypes is recommended for datasets with mixed numerical and categorical \"\n",
    "            \"variables. It extends K-means to handle categorical features using a combined \"\n",
    "            \"distance metric (Euclidean for numerical, matching for categorical). This is \"\n",
    "            \"particularly suitable for building energy data where categorical variables like \"\n",
    "            \"building type and region are important clustering features.\"\n",
    "        )\n",
    "    \n",
    "    elif needs_outliers and not size_constraint:\n",
    "        final_recommendation = \"DBSCAN\"\n",
    "        alternatives = [\"HDBSCAN\", \"K-means with outlier removal\"]\n",
    "        confidence = \"High\"\n",
    "        rationale = (\n",
    "            \"DBSCAN is recommended when outlier detection is a priority. It does not force \"\n",
    "            \"all points into clusters and explicitly labels outliers as noise.\"\n",
    "        )\n",
    "    \n",
    "    elif needs_hierarchy and not size_constraint:\n",
    "        final_recommendation = \"Hierarchical Clustering (Ward linkage)\"\n",
    "        alternatives = [\"Agglomerative with complete linkage\", \"BIRCH\"]\n",
    "        confidence = \"High\"\n",
    "        rationale = (\n",
    "            \"Hierarchical clustering is recommended when nested cluster structures are needed. \"\n",
    "            \"Ward linkage minimises within-cluster variance and produces interpretable dendrograms.\"\n",
    "        )\n",
    "    \n",
    "    elif size_constraint == 'very_large':\n",
    "        final_recommendation = \"Mini-batch K-means\"\n",
    "        alternatives = [\"K-means with sampling\", \"BIRCH\"]\n",
    "        confidence = \"High\"\n",
    "        rationale = (\n",
    "            \"Mini-batch K-means is recommended for very large datasets due to its computational \"\n",
    "            \"efficiency. It processes data in batches rather than requiring all data in memory.\"\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        final_recommendation = \"K-means\"\n",
    "        alternatives = [\"K-medoids\", \"Gaussian Mixture Models\"]\n",
    "        confidence = \"High\"\n",
    "        rationale = (\n",
    "            \"K-means is recommended as a robust default for numerical data with balanced clusters. \"\n",
    "            \"It is computationally efficient and produces interpretable centroids for benchmarking.\"\n",
    "        )\n",
    "    \n",
    "    # Print recommendation\n",
    "    print(f\"\\n  RECOMMENDED ALGORITHM: {final_recommendation}\")\n",
    "    print(f\"  ALTERNATIVES: {', '.join(alternatives)}\")\n",
    "    print(f\"  CONFIDENCE: {confidence}\")\n",
    "    print(f\"\\n  RATIONALE:\")\n",
    "    print(f\"  {rationale}\")\n",
    "    \n",
    "    # Print decision path\n",
    "    print(f\"\\nüìã DECISION PATH:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, (level, decision) in enumerate(decisions, 1):\n",
    "        print(f\"  {i}. [{level}] {decision}\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return {\n",
    "        'recommendation': final_recommendation,\n",
    "        'alternatives': alternatives,\n",
    "        'decision_path': decisions,\n",
    "        'confidence': confidence,\n",
    "        'rationale': rationale\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361b584",
   "metadata": {},
   "source": [
    "## 4. Apply to BDG2 Dataset\n",
    "\n",
    "The following cell applies the decision tree to the characteristics of the BDG2 building energy dataset analysed in the data quality assessment. This demonstrates how the decision tree provides a systematic, documented recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2baa3320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying decision tree to BDG2 dataset characteristics...\n",
      "\n",
      "======================================================================\n",
      "ALGORITHM DECISION TREE FOR CLUSTERING\n",
      "======================================================================\n",
      "\n",
      "üìä LEVEL 1: Data Type Assessment\n",
      "----------------------------------------\n",
      "  ‚Üí Mixed data types detected ‚Üí K-Prototypes or Gower distance required\n",
      "\n",
      "üìè LEVEL 2: Sample Size Assessment (n=5,902)\n",
      "----------------------------------------\n",
      "  ‚Üí Large dataset (5,000-50,000) ‚Üí K-means/K-Prototypes preferred\n",
      "\n",
      "üè¢ LEVEL 3: Domain Requirements (domain=building_energy)\n",
      "----------------------------------------\n",
      "  ‚Üí Building energy benchmarking ‚Üí Peer group identification priority\n",
      "  ‚Üí Peer group identification needed ‚Üí Centroid-based clustering preferred\n",
      "\n",
      "‚öôÔ∏è LEVEL 4: Special Requirements\n",
      "----------------------------------------\n",
      "  ‚Üí High interpretability needed ‚Üí Centroid-based methods preferred\n",
      "\n",
      "üéØ FINAL RECOMMENDATION\n",
      "======================================================================\n",
      "\n",
      "  RECOMMENDED ALGORITHM: K-Prototypes\n",
      "  ALTERNATIVES: Gower distance + Hierarchical, Encode categoricals + K-means\n",
      "  CONFIDENCE: High\n",
      "\n",
      "  RATIONALE:\n",
      "  K-Prototypes is recommended for datasets with mixed numerical and categorical variables. It extends K-means to handle categorical features using a combined distance metric (Euclidean for numerical, matching for categorical). This is particularly suitable for building energy data where categorical variables like building type and region are important clustering features.\n",
      "\n",
      "üìã DECISION PATH:\n",
      "----------------------------------------\n",
      "  1. [Data Type] Mixed data types detected ‚Üí K-Prototypes or Gower distance required\n",
      "  2. [Sample Size] Large dataset (5,000-50,000) ‚Üí K-means/K-Prototypes preferred\n",
      "  3. [Domain] Building energy benchmarking ‚Üí Peer group identification priority\n",
      "  4. [Peer Groups] Peer group identification needed ‚Üí Centroid-based clustering preferred\n",
      "  5. [Interpretability] High interpretability needed ‚Üí Centroid-based methods preferred\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define BDG2 dataset characteristics\n",
    "# (Based on data quality assessment findings)\n",
    "\n",
    "bdg2_data_characteristics = {\n",
    "    'n_samples': 5902,\n",
    "    'n_features': 15,\n",
    "    'has_categorical': True,   # primaryspaceusage, country, region\n",
    "    'has_missing': True,       # 47% missing yearbuilt\n",
    "    'outlier_proportion': 0.05 # Estimated after log transformation\n",
    "}\n",
    "\n",
    "bdg2_domain_requirements = {\n",
    "    'domain': 'building_energy',\n",
    "    'outlier_detection': False,  # Outliers handled in preprocessing\n",
    "    'hierarchy': False,          # Flat peer groups preferred\n",
    "    'peer_groups': True,         # Primary goal\n",
    "    'interpretability': 'high'   # Need interpretable clusters for benchmarking\n",
    "}\n",
    "\n",
    "bdg2_computational_constraints = {\n",
    "    'time_minutes': 60,\n",
    "    'memory_gb': 8.0,\n",
    "    'need_reproducibility': True\n",
    "}\n",
    "\n",
    "# Apply decision tree\n",
    "print(\"Applying decision tree to BDG2 dataset characteristics...\\n\")\n",
    "result = algorithm_decision_tree(\n",
    "    bdg2_data_characteristics,\n",
    "    bdg2_domain_requirements,\n",
    "    bdg2_computational_constraints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf5d2c",
   "metadata": {},
   "source": [
    "## 5. Implementation Guidance\n",
    "\n",
    "The following provides practical implementation guidance for the recommended K-Prototypes algorithm, including preprocessing requirements and validation approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2168bc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "IMPLEMENTATION GUIDANCE: K-Prototypes\n",
      "======================================================================\n",
      "\n",
      "üì¶ LIBRARY: kmodes\n",
      "   Install: pip install kmodes\n",
      "\n",
      "üîß PREPROCESSING STEPS:\n",
      "   1. Apply log transformation to skewed numerical variables (total_meter_reading, sqm)\n",
      "   2. Scale numerical features using RobustScaler (handles remaining outliers)\n",
      "   3. Encode categorical variables as integers (primaryspaceusage, country, region)\n",
      "   4. Handle missing values before clustering (imputation or exclusion)\n",
      "\n",
      "‚öôÔ∏è KEY PARAMETERS:\n",
      "   - n_clusters: Determine via Elbow method or Silhouette score (try 3-10)\n",
      "   - init: 'Huang' (default) or 'Cao' for better initialisation\n",
      "   - gamma: Weight for categorical variables (default=None uses auto-calculation)\n",
      "   - n_init: 10-20 random initialisations for stability\n",
      "   - max_iter: 100-300 iterations typically sufficient\n",
      "\n",
      "‚úÖ VALIDATION METHODS:\n",
      "   1. Silhouette score (mixed-type version)\n",
      "   2. Bootstrap stability assessment (100-200 resamples)\n",
      "   3. Within-cluster variance analysis\n",
      "   4. Visual inspection of cluster characteristics\n",
      "\n",
      "üíª CODE EXAMPLE:\n",
      "\n",
      "from kmodes.kprototypes import KPrototypes\n",
      "import numpy as np\n",
      "\n",
      "# Assume df_preprocessed has numerical and categorical columns\n",
      "# Categorical columns should be integer-encoded\n",
      "\n",
      "# Identify categorical column indices\n",
      "categorical_indices = [df.columns.get_loc(col) for col in ['primaryspaceusage', 'country', 'region']]\n",
      "\n",
      "# Fit K-Prototypes\n",
      "kproto = KPrototypes(n_clusters=5, init='Huang', n_init=10, random_state=42)\n",
      "clusters = kproto.fit_predict(df_preprocessed.values, categorical=categorical_indices)\n",
      "\n",
      "# Add cluster labels to dataframe\n",
      "df_preprocessed['cluster'] = clusters\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_implementation_guidance(algorithm: str):\n",
    "    \"\"\"\n",
    "    Provides detailed implementation guidance for a given algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    algorithm : str\n",
    "        Name of the recommended algorithm\n",
    "    \"\"\"\n",
    "    \n",
    "    guidance = {\n",
    "        'K-Prototypes': {\n",
    "            'library': 'kmodes',\n",
    "            'install': 'pip install kmodes',\n",
    "            'preprocessing': [\n",
    "                'Apply log transformation to skewed numerical variables (total_meter_reading, sqm)',\n",
    "                'Scale numerical features using RobustScaler (handles remaining outliers)',\n",
    "                'Encode categorical variables as integers (primaryspaceusage, country, region)',\n",
    "                'Handle missing values before clustering (imputation or exclusion)'\n",
    "            ],\n",
    "            'parameters': {\n",
    "                'n_clusters': 'Determine via Elbow method or Silhouette score (try 3-10)',\n",
    "                'init': \"'Huang' (default) or 'Cao' for better initialisation\",\n",
    "                'gamma': 'Weight for categorical variables (default=None uses auto-calculation)',\n",
    "                'n_init': '10-20 random initialisations for stability',\n",
    "                'max_iter': '100-300 iterations typically sufficient'\n",
    "            },\n",
    "            'validation': [\n",
    "                'Silhouette score (mixed-type version)',\n",
    "                'Bootstrap stability assessment (100-200 resamples)',\n",
    "                'Within-cluster variance analysis',\n",
    "                'Visual inspection of cluster characteristics'\n",
    "            ],\n",
    "            'code_example': '''\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_preprocessed has numerical and categorical columns\n",
    "# Categorical columns should be integer-encoded\n",
    "\n",
    "# Identify categorical column indices\n",
    "categorical_indices = [df.columns.get_loc(col) for col in ['primaryspaceusage', 'country', 'region']]\n",
    "\n",
    "# Fit K-Prototypes\n",
    "kproto = KPrototypes(n_clusters=5, init='Huang', n_init=10, random_state=42)\n",
    "clusters = kproto.fit_predict(df_preprocessed.values, categorical=categorical_indices)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "df_preprocessed['cluster'] = clusters\n",
    "'''\n",
    "        },\n",
    "        \n",
    "        'K-means': {\n",
    "            'library': 'scikit-learn',\n",
    "            'install': 'pip install scikit-learn',\n",
    "            'preprocessing': [\n",
    "                'One-hot encode categorical variables',\n",
    "                'Apply log transformation to skewed numerical variables',\n",
    "                'Standardise all features using StandardScaler or RobustScaler'\n",
    "            ],\n",
    "            'parameters': {\n",
    "                'n_clusters': 'Determine via Elbow method or Silhouette score',\n",
    "                'init': \"'k-means++' for smart initialisation\",\n",
    "                'n_init': '10-20 random initialisations',\n",
    "                'max_iter': '300 iterations'\n",
    "            },\n",
    "            'validation': [\n",
    "                'Silhouette score',\n",
    "                'Davies-Bouldin index',\n",
    "                'Elbow method (inertia)',\n",
    "                'Bootstrap stability assessment'\n",
    "            ],\n",
    "            'code_example': '''\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardise features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_numerical)\n",
    "\n",
    "# Fit K-means\n",
    "kmeans = KMeans(n_clusters=5, init='k-means++', n_init=10, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "'''\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if algorithm not in guidance:\n",
    "        print(f\"Implementation guidance not available for: {algorithm}\")\n",
    "        return\n",
    "    \n",
    "    g = guidance[algorithm]\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(f\"IMPLEMENTATION GUIDANCE: {algorithm}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nüì¶ LIBRARY: {g['library']}\")\n",
    "    print(f\"   Install: {g['install']}\")\n",
    "    \n",
    "    print(f\"\\nüîß PREPROCESSING STEPS:\")\n",
    "    for i, step in enumerate(g['preprocessing'], 1):\n",
    "        print(f\"   {i}. {step}\")\n",
    "    \n",
    "    print(f\"\\n‚öôÔ∏è KEY PARAMETERS:\")\n",
    "    for param, desc in g['parameters'].items():\n",
    "        print(f\"   - {param}: {desc}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ VALIDATION METHODS:\")\n",
    "    for i, method in enumerate(g['validation'], 1):\n",
    "        print(f\"   {i}. {method}\")\n",
    "    \n",
    "    print(f\"\\nüíª CODE EXAMPLE:\")\n",
    "    print(g['code_example'])\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# Print guidance for K-Prototypes\n",
    "print_implementation_guidance('K-Prototypes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27e0a1",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "### Decision Tree Outcome for BDG2 Dataset\n",
    "\n",
    "Based on the systematic evaluation through the algorithm decision tree:\n",
    "\n",
    "| Assessment Level | Finding |\n",
    "|------------------|---------|\n",
    "| **Data Type** | Mixed (numerical + categorical) ‚Üí K-Prototypes required |\n",
    "| **Sample Size** | 5,902 samples ‚Üí Medium dataset, most algorithms feasible |\n",
    "| **Domain** | Building energy benchmarking ‚Üí Peer group identification priority |\n",
    "| **Interpretability** | High requirement ‚Üí Centroid-based methods preferred |\n",
    "\n",
    "### Final Recommendation\n",
    "\n",
    "**K-Prototypes** is recommended for clustering the BDG2 building energy dataset because:\n",
    "\n",
    "1. **Mixed data types**: The dataset contains both numerical variables (total_meter_reading, sqm, climate variables) and categorical variables (primaryspaceusage, country, region)\n",
    "\n",
    "2. **Peer group identification**: K-Prototypes produces interpretable cluster centroids that can serve as building energy benchmarks\n",
    "\n",
    "3. **Computational efficiency**: The algorithm scales well to the dataset size (5,902 samples)\n",
    "\n",
    "4. **Categorical handling**: Unlike encoding-based approaches, K-Prototypes uses a theoretically appropriate distance metric for categorical variables\n",
    "\n",
    "### Alternative Approaches\n",
    "\n",
    "If K-Prototypes proves unsuitable:\n",
    "- **Gower distance + Hierarchical**: For exploring cluster hierarchy\n",
    "- **Encode categoricals + K-means**: Simpler implementation but loses categorical structure\n",
    "\n",
    "### Validation Strategy\n",
    "\n",
    "Implement bootstrap stability assessment with 100-200 resamples to ensure clusters are robust and not artifacts of the specific sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb24b163",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Final Algorithm Selection Framework\n",
    "\n",
    "This section provides a comprehensive, structured framework documenting the complete algorithm selection process. This framework ensures transparency, reproducibility, and stakeholder trust by synthesising all considerations into a coherent decision record.\n",
    "\n",
    "### Why Documentation Matters\n",
    "\n",
    "A clear, structured report of the selection process:\n",
    "- **Transparency**: Stakeholders can understand and scrutinise the reasoning\n",
    "- **Reproducibility**: Future analysts can replicate or update the analysis\n",
    "- **Audit trail**: Decisions are traceable and defensible\n",
    "- **Knowledge transfer**: New team members can understand the rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3317d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_algorithm_selection_framework(\n",
    "    data_profile: Dict[str, Any],\n",
    "    domain_requirements: Dict[str, Any],\n",
    "    computational_constraints: Dict[str, Any],\n",
    "    stakeholder_needs: Dict[str, Any],\n",
    "    algorithm_candidates: List[Dict[str, Any]],\n",
    "    validation_results: Dict[str, Any],\n",
    "    final_recommendation: Dict[str, Any]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a comprehensive algorithm selection framework document.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_profile : dict\n",
    "        Dataset characteristics including sample size, features, missing data,\n",
    "        distributions, and correlations\n",
    "    domain_requirements : dict\n",
    "        Specific domain goals and requirements\n",
    "    computational_constraints : dict\n",
    "        Time, memory, and processing environment constraints\n",
    "    stakeholder_needs : dict\n",
    "        Interpretability, visual simplicity, cluster number preferences\n",
    "    algorithm_candidates : list of dict\n",
    "        Shortlisted algorithms with rationale for each\n",
    "    validation_results : dict\n",
    "        Statistical metrics, stability scores, domain benchmarks\n",
    "    final_recommendation : dict\n",
    "        Chosen algorithm(s), parameters, and justification\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str : Formatted framework document\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = []\n",
    "    doc.append(\"=\" * 80)\n",
    "    doc.append(\"FINAL ALGORITHM SELECTION FRAMEWORK\")\n",
    "    doc.append(\"Building Energy Clustering for Peer Group Identification\")\n",
    "    doc.append(\"=\" * 80)\n",
    "    doc.append(f\"\\nDocument Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 1. DATA PROFILE SUMMARY\n",
    "    # =========================================================================\n",
    "    doc.append(\"\\n\" + \"=\" * 80)\n",
    "    doc.append(\"1. DATA PROFILE SUMMARY\")\n",
    "    doc.append(\"=\" * 80)\n",
    "    \n",
    "    doc.append(f\"\\nüìä Dataset Overview:\")\n",
    "    doc.append(f\"   ‚Ä¢ Sample size: {data_profile.get('n_samples', 'N/A'):,} records\")\n",
    "    doc.append(f\"   ‚Ä¢ Feature count: {data_profile.get('n_features', 'N/A')} variables\")\n",
    "    doc.append(f\"   ‚Ä¢ Data source: {data_profile.get('source', 'N/A')}\")\n",
    "    doc.append(f\"   ‚Ä¢ Time period: {data_profile.get('time_period', 'N/A')}\")\n",
    "    \n",
    "    doc.append(f\"\\nüìã Variable Types:\")\n",
    "    numerical = data_profile.get('numerical_features', [])\n",
    "    categorical = data_profile.get('categorical_features', [])\n",
    "    doc.append(f\"   ‚Ä¢ Numerical ({len(numerical)}): {', '.join(numerical[:5])}{'...' if len(numerical) > 5 else ''}\")\n",
    "    doc.append(f\"   ‚Ä¢ Categorical ({len(categorical)}): {', '.join(categorical)}\")\n",
    "    \n",
    "    doc.append(f\"\\n‚ö†Ô∏è Data Quality Issues:\")\n",
    "    missing = data_profile.get('missing_data', {})\n",
    "    for var, pct in missing.items():\n",
    "        doc.append(f\"   ‚Ä¢ {var}: {pct:.1%} missing\")\n",
    "    \n",
    "    doc.append(f\"\\nüìà Distribution Characteristics:\")\n",
    "    distributions = data_profile.get('distributions', {})\n",
    "    for var, dist in distributions.items():\n",
    "        doc.append(f\"   ‚Ä¢ {var}: {dist}\")\n",
    "    \n",
    "    doc.append(f\"\\nüîó Correlation Issues:\")\n",
    "    correlations = data_profile.get('correlation_issues', [])\n",
    "    for issue in correlations:\n",
    "        doc.append(f\"   ‚Ä¢ {issue}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 2. DOMAIN REQUIREMENTS\n",
    "    # =========================================================================\n",
    "    doc.append(\"\\n\" + \"=\" * 80)\n",
    "    doc.append(\"2. DOMAIN REQUIREMENTS\")\n",
    "    doc.append(\"=\" * 80)\n",
    "    \n",
    "    doc.append(f\"\\nüéØ Primary Goal:\")\n",
    "    doc.append(f\"   {domain_requirements.get('primary_goal', 'N/A')}\")\n",
    "    \n",
    "    doc.append(f\"\\nüè¢ Domain Context:\")\n",
    "    doc.append(f\"   {domain_requirements.get('domain_context', 'N/A')}\")\n",
    "    \n",
    "    doc.append(f\"\\nüìå Specific Requirements:\")\n",
    "    requirements = domain_requirements.get('specific_requirements', [])\n",
    "    for req in requirements:\n",
    "        doc.append(f\"   ‚Ä¢ {req}\")\n",
    "    \n",
    "    doc.append(f\"\\nüéØ Success Criteria:\")\n",
    "    criteria = domain_requirements.get('success_criteria', [])\n",
    "    for criterion in criteria:\n",
    "        doc.append(f\"   ‚Ä¢ {criterion}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 3. COMPUTATIONAL CONSTRAINTS\n",
    "    # =========================================================================\n",
    "    doc.append(\"\\n\" + \"=\" * 80)\n",
    "    doc.append(\"3. COMPUTATIONAL CONSTRAINTS\")\n",
    "    doc.append(\"=\" * 80)\n",
    "    \n",
    "    doc.append(f\"\\n‚è±Ô∏è Time Constraints:\")\n",
    "    doc.append(f\"   ‚Ä¢ Maximum runtime: {computational_constraints.get('max_runtime', 'N/A')}\")\n",
    "    doc.append(f\"   ‚Ä¢ Frequency of re-runs: {computational_constraints.get('rerun_frequency', 'N/A')}\")\n",
    "    \n",
    "    doc.append(f\"\\nüíæ Memory Constraints:\")\n",
    "    doc.append(f\"   ‚Ä¢ Available RAM: {computational_constraints.get('available_ram', 'N/A')}\")\n",
    "    doc.append(f\"   ‚Ä¢ Data fits in memory: {computational_constraints.get('fits_in_memory', 'N/A')}\")\n",
    "    \n",
    "    doc.append(f\"\\nüñ•Ô∏è Processing Environment:\")\n",
    "    doc.append(f\"   ‚Ä¢ Environment: {computational_constraints.get('environment', 'N/A')}\")\n",
    "    doc.append(f\"   ‚Ä¢ Reproducibility required: {computational_constraints.get('reproducibility', 'N/A')}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 4. STAKEHOLDER NEEDS\n",
    "    # =========================================================================\n",
    "    doc.append(\"\\n\" + \"=\" * 80)\n",
    "    doc.append(\"4. STAKEHOLDER NEEDS\")\n",
    "    doc.append(\"=\" * 80)\n",
    "    \n",
    "    doc.append(f\"\\nüë• Primary Stakeholders:\")\n",
    "    stakeholders = stakeholder_needs.get('stakeholders', [])\n",
    "    for stakeholder in stakeholders:\n",
    "        doc.append(f\"   ‚Ä¢ {stakeholder}\")\n",
    "    \n",
    "    doc.append(f\"\\nüîç Interpretability Requirements:\")\n",
    "    doc.append(f\"   ‚Ä¢ Level required: {stakeholder_needs.get('interpretability_level', 'N/A')}\")\n",
    "    doc.append(f\"   ‚Ä¢ Explanation needs: {stakeholder_needs.get('explanation_needs', 'N/A')}\")\n",
    "    \n",
    "    doc.append(f\"\\nüìä Visual Requirements:\")\n",
    "    doc.append(f\"   ‚Ä¢ Simplicity level: {stakeholder_needs.get('visual_simplicity', 'N/A')}\")\n",
    "    doc.append(f\"   ‚Ä¢ Visualisation types: {stakeholder_needs.get('viz_types', 'N/A')}\")\n",
    "    \n",
    "    doc.append(f\"\\nüî¢ Cluster Preferences:\")\n",
    "    doc.append(f\"   ‚Ä¢ Expected range: {stakeholder_needs.get('cluster_range', 'N/A')}\")\n",
    "    doc.append(f\"   ‚Ä¢ Flexibility: {stakeholder_needs.get('cluster_flexibility', 'N/A')}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 5. ALGORITHM CANDIDATES\n",
    "    # =========================================================================\n",
    "    doc.append(\"\\n\" + \"=\" * 80)\n",
    "    doc.append(\"5. ALGORITHM CANDIDATES\")\n",
    "    doc.append(\"=\" * 80)\n",
    "    \n",
    "    for i, candidate in enumerate(algorithm_candidates, 1):\n",
    "        doc.append(f\"\\nüìå Candidate {i}: {candidate.get('name', 'N/A')}\")\n",
    "        doc.append(f\"   Rationale: {candidate.get('rationale', 'N/A')}\")\n",
    "        doc.append(f\"   Strengths:\")\n",
    "        for strength in candidate.get('strengths', []):\n",
    "            doc.append(f\"      ‚úì {strength}\")\n",
    "        doc.append(f\"   Limitations:\")\n",
    "        for limitation in candidate.get('limitations', []):\n",
    "            doc.append(f\"      ‚úó {limitation}\")\n",
    "        doc.append(f\"   Suitability Score: {candidate.get('suitability_score', 'N/A')}/10\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 6. VALIDATION RESULTS\n",
    "    # =========================================================================\n",
    "    doc.append(\"\\n\" + \"=\" * 80)\n",
    "    doc.append(\"6. VALIDATION RESULTS\")\n",
    "    doc.append(\"=\" * 80)\n",
    "    \n",
    "    doc.append(f\"\\nüìè Statistical Metrics:\")\n",
    "    metrics = validation_results.get('metrics', {})\n",
    "    for metric, value in metrics.items():\n",
    "        doc.append(f\"   ‚Ä¢ {metric}: {value}\")\n",
    "    \n",
    "    doc.append(f\"\\nüîÑ Stability Assessment:\")\n",
    "    stability = validation_results.get('stability', {})\n",
    "    doc.append(f\"   ‚Ä¢ Method: {stability.get('method', 'N/A')}\")\n",
    "    doc.append(f\"   ‚Ä¢ Score: {stability.get('score', 'N/A')}\")\n",
    "    doc.append(f\"   ‚Ä¢ Interpretation: {stability.get('interpretation', 'N/A')}\")\n",
    "    \n",
    "    doc.append(f\"\\nüè¢ Domain Benchmarks:\")\n",
    "    benchmarks = validation_results.get('domain_benchmarks', [])\n",
    "    for benchmark in benchmarks:\n",
    "        doc.append(f\"   ‚Ä¢ {benchmark}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 7. FINAL RECOMMENDATION\n",
    "    # =========================================================================\n",
    "    doc.append(\"\\n\" + \"=\" * 80)\n",
    "    doc.append(\"7. FINAL RECOMMENDATION\")\n",
    "    doc.append(\"=\" * 80)\n",
    "    \n",
    "    doc.append(f\"\\nüéØ RECOMMENDED ALGORITHM: {final_recommendation.get('algorithm', 'N/A')}\")\n",
    "    \n",
    "    doc.append(f\"\\n‚öôÔ∏è Recommended Parameters:\")\n",
    "    params = final_recommendation.get('parameters', {})\n",
    "    for param, value in params.items():\n",
    "        doc.append(f\"   ‚Ä¢ {param}: {value}\")\n",
    "    \n",
    "    doc.append(f\"\\nüìù Justification:\")\n",
    "    justification = final_recommendation.get('justification', [])\n",
    "    for j in justification:\n",
    "        doc.append(f\"   {j}\")\n",
    "    \n",
    "    doc.append(f\"\\nüîÑ Alternative Approaches:\")\n",
    "    alternatives = final_recommendation.get('alternatives', [])\n",
    "    for alt in alternatives:\n",
    "        doc.append(f\"   ‚Ä¢ {alt}\")\n",
    "    \n",
    "    doc.append(f\"\\n‚ö†Ô∏è Caveats and Limitations:\")\n",
    "    caveats = final_recommendation.get('caveats', [])\n",
    "    for caveat in caveats:\n",
    "        doc.append(f\"   ‚Ä¢ {caveat}\")\n",
    "    \n",
    "    doc.append(\"\\n\" + \"=\" * 80)\n",
    "    doc.append(\"END OF FRAMEWORK DOCUMENT\")\n",
    "    doc.append(\"=\" * 80)\n",
    "    \n",
    "    return \"\\n\".join(doc)\n",
    "\n",
    "\n",
    "# Import pandas for timestamp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b05a9",
   "metadata": {},
   "source": [
    "### 7.1 Apply Framework to BDG2 Dataset\n",
    "\n",
    "The following cell populates the framework with the specific details from the BDG2 building energy dataset analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83812bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BDG2 DATASET - COMPLETE FRAMEWORK INPUTS\n",
    "# ============================================================================\n",
    "\n",
    "# 1. DATA PROFILE SUMMARY\n",
    "bdg2_data_profile = {\n",
    "    'n_samples': 5902,\n",
    "    'n_features': 15,\n",
    "    'source': 'Building Data Genome Project 2 (BDG2) - Nature Scientific Data',\n",
    "    'time_period': '2016-2017 (hourly data aggregated to annual)',\n",
    "    'numerical_features': [\n",
    "        'total_meter_reading', 'sqm', 'yearbuilt',\n",
    "        'heating_degree_days_mean', 'cooling_degree_days_mean',\n",
    "        'average_temperature_mean', 'average_humidity_mean'\n",
    "    ],\n",
    "    'categorical_features': ['primaryspaceusage', 'country', 'region'],\n",
    "    'missing_data': {\n",
    "        'yearbuilt': 0.47,  # 47% missing\n",
    "        'other_variables': 0.0\n",
    "    },\n",
    "    'distributions': {\n",
    "        'total_meter_reading': 'Highly right-skewed (requires log transformation)',\n",
    "        'sqm': 'Right-skewed (requires log transformation)',\n",
    "        'climate_variables': 'Approximately normal after transformation'\n",
    "    },\n",
    "    'correlation_issues': [\n",
    "        'Climate variables show high multicollinearity (HDD-CDD r=-0.89)',\n",
    "        'Temperature correlated with degree days',\n",
    "        'Consider PCA or feature selection for climate variables'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 2. DOMAIN REQUIREMENTS\n",
    "bdg2_domain_requirements_full = {\n",
    "    'primary_goal': 'Identify peer groups of similar buildings for energy benchmarking and retrofit prioritisation',\n",
    "    'domain_context': 'Building energy performance assessment for demand flexibility and sustainability initiatives',\n",
    "    'specific_requirements': [\n",
    "        'Cluster buildings by energy consumption patterns',\n",
    "        'Account for building characteristics (size, type, age)',\n",
    "        'Consider climate context for fair comparison',\n",
    "        'Identify underperforming buildings within peer groups',\n",
    "        'Support targeting of retrofit interventions'\n",
    "    ],\n",
    "    'success_criteria': [\n",
    "        'Clusters are interpretable to building managers',\n",
    "        'Within-cluster buildings are genuinely comparable',\n",
    "        'Clusters are stable across bootstrap resamples',\n",
    "        'Cluster centroids can serve as benchmarks'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 3. COMPUTATIONAL CONSTRAINTS\n",
    "bdg2_computational_constraints_full = {\n",
    "    'max_runtime': '< 60 minutes for full analysis',\n",
    "    'rerun_frequency': 'Ad-hoc (not real-time)',\n",
    "    'available_ram': '8-16 GB typical',\n",
    "    'fits_in_memory': 'Yes (5,902 rows √ó 15 columns)',\n",
    "    'environment': 'Local Python/Jupyter environment',\n",
    "    'reproducibility': 'Yes - random seeds required'\n",
    "}\n",
    "\n",
    "# 4. STAKEHOLDER NEEDS\n",
    "bdg2_stakeholder_needs = {\n",
    "    'stakeholders': [\n",
    "        'Building energy managers',\n",
    "        'Sustainability officers',\n",
    "        'Policy makers',\n",
    "        'Research analysts'\n",
    "    ],\n",
    "    'interpretability_level': 'High - clusters must be explainable in domain terms',\n",
    "    'explanation_needs': 'Cluster centroids as benchmark profiles, clear membership criteria',\n",
    "    'visual_simplicity': 'Medium - 2D projections acceptable, dendrograms if hierarchical',\n",
    "    'viz_types': 'Scatter plots, parallel coordinates, cluster profiles',\n",
    "    'cluster_range': '4-8 clusters (manageable for practical benchmarking)',\n",
    "    'cluster_flexibility': 'Some flexibility, but prefer fewer well-defined groups'\n",
    "}\n",
    "\n",
    "# 5. ALGORITHM CANDIDATES\n",
    "bdg2_algorithm_candidates = [\n",
    "    {\n",
    "        'name': 'K-Prototypes',\n",
    "        'rationale': 'Native handling of mixed numerical and categorical data',\n",
    "        'strengths': [\n",
    "            'Theoretically appropriate for mixed data types',\n",
    "            'Produces interpretable cluster centroids',\n",
    "            'Computationally efficient for medium datasets',\n",
    "            'Well-established in building energy literature'\n",
    "        ],\n",
    "        'limitations': [\n",
    "            'Requires pre-specifying number of clusters',\n",
    "            'Sensitive to initialisation (mitigated by multiple runs)',\n",
    "            'Assumes spherical clusters in numerical space'\n",
    "        ],\n",
    "        'suitability_score': 9\n",
    "    },\n",
    "    {\n",
    "        'name': 'Gower Distance + Hierarchical Clustering',\n",
    "        'rationale': 'Flexible distance metric for mixed data with hierarchical structure',\n",
    "        'strengths': [\n",
    "            'Handles mixed data through Gower distance',\n",
    "            'Provides hierarchical structure (dendrogram)',\n",
    "            'No need to pre-specify cluster count'\n",
    "        ],\n",
    "        'limitations': [\n",
    "            'Computationally expensive O(n¬≤) for distance matrix',\n",
    "            'Less interpretable centroids',\n",
    "            'May be slow for larger datasets'\n",
    "        ],\n",
    "        'suitability_score': 7\n",
    "    },\n",
    "    {\n",
    "        'name': 'One-Hot Encoding + K-means',\n",
    "        'rationale': 'Simple approach using standard K-means after encoding',\n",
    "        'strengths': [\n",
    "            'Simple implementation',\n",
    "            'Well-understood algorithm',\n",
    "            'Fast computation'\n",
    "        ],\n",
    "        'limitations': [\n",
    "            'Loses categorical structure through encoding',\n",
    "            'High dimensionality with many categories',\n",
    "            'May distort distances'\n",
    "        ],\n",
    "        'suitability_score': 6\n",
    "    }\n",
    "]\n",
    "\n",
    "# 6. VALIDATION RESULTS (Planned/Expected)\n",
    "bdg2_validation_results = {\n",
    "    'metrics': {\n",
    "        'Silhouette Score': 'Target > 0.3 (moderate separation)',\n",
    "        'Davies-Bouldin Index': 'Target < 1.0 (compact, separated)',\n",
    "        'Within-cluster variance': 'Minimise via elbow method'\n",
    "    },\n",
    "    'stability': {\n",
    "        'method': 'Bootstrap resampling (100-200 iterations)',\n",
    "        'score': 'Target > 80% membership consistency',\n",
    "        'interpretation': 'Clusters should remain stable across resamples'\n",
    "    },\n",
    "    'domain_benchmarks': [\n",
    "        'Energy intensity (kWh/m¬≤) variance within clusters should be low',\n",
    "        'Clusters should differ meaningfully in average energy performance',\n",
    "        'Building types should show logical clustering patterns'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 7. FINAL RECOMMENDATION\n",
    "bdg2_final_recommendation = {\n",
    "    'algorithm': 'K-Prototypes',\n",
    "    'parameters': {\n",
    "        'n_clusters': '5-7 (determine via elbow/silhouette)',\n",
    "        'init': 'Huang',\n",
    "        'n_init': '20 (multiple initialisations for stability)',\n",
    "        'gamma': 'Auto (algorithm-determined categorical weight)',\n",
    "        'random_state': '42 (for reproducibility)'\n",
    "    },\n",
    "    'justification': [\n",
    "        '1. Mixed data handling: K-Prototypes natively handles both numerical features',\n",
    "        '   (energy consumption, floor area, climate variables) and categorical features',\n",
    "        '   (building type, region) without requiring encoding that distorts distances.',\n",
    "        '',\n",
    "        '2. Interpretable centroids: Cluster centres provide meaningful benchmark',\n",
    "        '   profiles (e.g., \"large office buildings in hot climates\") that stakeholders',\n",
    "        '   can understand and use for comparative benchmarking.',\n",
    "        '',\n",
    "        '3. Computational feasibility: The algorithm handles the dataset size (5,902',\n",
    "        '   records) efficiently, allowing for bootstrap validation.',\n",
    "        '',\n",
    "        '4. Domain precedent: K-Prototypes has been successfully applied in building',\n",
    "        '   energy benchmarking studies in the peer-reviewed literature.'\n",
    "    ],\n",
    "    'alternatives': [\n",
    "        'Gower + Hierarchical: If cluster hierarchy exploration is needed',\n",
    "        'K-means with encoding: If categorical variables prove less important',\n",
    "        'DBSCAN: If outlier detection becomes a primary concern'\n",
    "    ],\n",
    "    'caveats': [\n",
    "        'Dataset age: Data from 2016-2017 may not reflect current building stock',\n",
    "        'Geographic bias: 80.8% USA concentration limits generalisability',\n",
    "        'Missing data: 47% missing yearbuilt requires careful handling',\n",
    "        'Validation needed: Bootstrap stability assessment should confirm robustness'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Generate the framework document\n",
    "framework_document = generate_algorithm_selection_framework(\n",
    "    data_profile=bdg2_data_profile,\n",
    "    domain_requirements=bdg2_domain_requirements_full,\n",
    "    computational_constraints=bdg2_computational_constraints_full,\n",
    "    stakeholder_needs=bdg2_stakeholder_needs,\n",
    "    algorithm_candidates=bdg2_algorithm_candidates,\n",
    "    validation_results=bdg2_validation_results,\n",
    "    final_recommendation=bdg2_final_recommendation\n",
    ")\n",
    "\n",
    "print(framework_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a3e59",
   "metadata": {},
   "source": [
    "### 7.2 Export Framework to File\n",
    "\n",
    "The framework can be exported as a standalone document for sharing with stakeholders or archiving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export framework document to file\n",
    "output_path = '../ALGORITHM_SELECTION_FRAMEWORK.md'\n",
    "\n",
    "# Convert to markdown format for better readability\n",
    "markdown_content = f\"\"\"# Algorithm Selection Framework\n",
    "## Building Energy Clustering for Peer Group Identification\n",
    "\n",
    "**Document Generated:** {pd.Timestamp.now().strftime('%Y-%m-%d')}\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data Profile Summary\n",
    "\n",
    "### Dataset Overview\n",
    "| Attribute | Value |\n",
    "|-----------|-------|\n",
    "| Sample Size | {bdg2_data_profile['n_samples']:,} records |\n",
    "| Feature Count | {bdg2_data_profile['n_features']} variables |\n",
    "| Data Source | {bdg2_data_profile['source']} |\n",
    "| Time Period | {bdg2_data_profile['time_period']} |\n",
    "\n",
    "### Variable Types\n",
    "- **Numerical ({len(bdg2_data_profile['numerical_features'])}):** {', '.join(bdg2_data_profile['numerical_features'])}\n",
    "- **Categorical ({len(bdg2_data_profile['categorical_features'])}):** {', '.join(bdg2_data_profile['categorical_features'])}\n",
    "\n",
    "### Data Quality Issues\n",
    "| Variable | Issue |\n",
    "|----------|-------|\n",
    "| yearbuilt | 47% missing values |\n",
    "| total_meter_reading | Highly right-skewed |\n",
    "| sqm | Right-skewed |\n",
    "| Climate variables | High multicollinearity (HDD-CDD r=-0.89) |\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Domain Requirements\n",
    "\n",
    "### Primary Goal\n",
    "{bdg2_domain_requirements_full['primary_goal']}\n",
    "\n",
    "### Domain Context\n",
    "{bdg2_domain_requirements_full['domain_context']}\n",
    "\n",
    "### Specific Requirements\n",
    "{chr(10).join(['- ' + req for req in bdg2_domain_requirements_full['specific_requirements']])}\n",
    "\n",
    "### Success Criteria\n",
    "{chr(10).join(['- ' + crit for crit in bdg2_domain_requirements_full['success_criteria']])}\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Computational Constraints\n",
    "\n",
    "| Constraint | Specification |\n",
    "|------------|---------------|\n",
    "| Maximum Runtime | {bdg2_computational_constraints_full['max_runtime']} |\n",
    "| Re-run Frequency | {bdg2_computational_constraints_full['rerun_frequency']} |\n",
    "| Available RAM | {bdg2_computational_constraints_full['available_ram']} |\n",
    "| Fits in Memory | {bdg2_computational_constraints_full['fits_in_memory']} |\n",
    "| Environment | {bdg2_computational_constraints_full['environment']} |\n",
    "| Reproducibility | {bdg2_computational_constraints_full['reproducibility']} |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Stakeholder Needs\n",
    "\n",
    "### Primary Stakeholders\n",
    "{chr(10).join(['- ' + s for s in bdg2_stakeholder_needs['stakeholders']])}\n",
    "\n",
    "### Requirements\n",
    "| Aspect | Requirement |\n",
    "|--------|-------------|\n",
    "| Interpretability | {bdg2_stakeholder_needs['interpretability_level']} |\n",
    "| Explanation Needs | {bdg2_stakeholder_needs['explanation_needs']} |\n",
    "| Visual Simplicity | {bdg2_stakeholder_needs['visual_simplicity']} |\n",
    "| Cluster Range | {bdg2_stakeholder_needs['cluster_range']} |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Algorithm Candidates\n",
    "\n",
    "### Candidate 1: K-Prototypes (Suitability: 9/10)\n",
    "**Rationale:** {bdg2_algorithm_candidates[0]['rationale']}\n",
    "\n",
    "**Strengths:**\n",
    "{chr(10).join(['- ' + s for s in bdg2_algorithm_candidates[0]['strengths']])}\n",
    "\n",
    "**Limitations:**\n",
    "{chr(10).join(['- ' + l for l in bdg2_algorithm_candidates[0]['limitations']])}\n",
    "\n",
    "### Candidate 2: Gower Distance + Hierarchical (Suitability: 7/10)\n",
    "**Rationale:** {bdg2_algorithm_candidates[1]['rationale']}\n",
    "\n",
    "**Strengths:**\n",
    "{chr(10).join(['- ' + s for s in bdg2_algorithm_candidates[1]['strengths']])}\n",
    "\n",
    "**Limitations:**\n",
    "{chr(10).join(['- ' + l for l in bdg2_algorithm_candidates[1]['limitations']])}\n",
    "\n",
    "### Candidate 3: One-Hot Encoding + K-means (Suitability: 6/10)\n",
    "**Rationale:** {bdg2_algorithm_candidates[2]['rationale']}\n",
    "\n",
    "**Strengths:**\n",
    "{chr(10).join(['- ' + s for s in bdg2_algorithm_candidates[2]['strengths']])}\n",
    "\n",
    "**Limitations:**\n",
    "{chr(10).join(['- ' + l for l in bdg2_algorithm_candidates[2]['limitations']])}\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Validation Strategy\n",
    "\n",
    "### Statistical Metrics (Targets)\n",
    "| Metric | Target |\n",
    "|--------|--------|\n",
    "| Silhouette Score | > 0.3 (moderate separation) |\n",
    "| Davies-Bouldin Index | < 1.0 (compact, separated) |\n",
    "| Within-cluster Variance | Minimise via elbow method |\n",
    "\n",
    "### Stability Assessment\n",
    "- **Method:** Bootstrap resampling (100-200 iterations)\n",
    "- **Target:** > 80% membership consistency\n",
    "- **Interpretation:** Clusters should remain stable across resamples\n",
    "\n",
    "### Domain Benchmarks\n",
    "{chr(10).join(['- ' + b for b in bdg2_validation_results['domain_benchmarks']])}\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Final Recommendation\n",
    "\n",
    "### Recommended Algorithm: **K-Prototypes**\n",
    "\n",
    "### Parameters\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| n_clusters | 5-7 (determine via elbow/silhouette) |\n",
    "| init | Huang |\n",
    "| n_init | 20 (multiple initialisations) |\n",
    "| gamma | Auto (algorithm-determined) |\n",
    "| random_state | 42 (reproducibility) |\n",
    "\n",
    "### Justification\n",
    "{chr(10).join(bdg2_final_recommendation['justification'])}\n",
    "\n",
    "### Alternative Approaches\n",
    "{chr(10).join(['- ' + a for a in bdg2_final_recommendation['alternatives']])}\n",
    "\n",
    "### Caveats and Limitations\n",
    "{chr(10).join(['- ' + c for c in bdg2_final_recommendation['caveats']])}\n",
    "\n",
    "---\n",
    "\n",
    "## Document Control\n",
    "\n",
    "| Version | Date | Author | Changes |\n",
    "|---------|------|--------|---------|\n",
    "| 1.0 | {pd.Timestamp.now().strftime('%Y-%m-%d')} | Algorithm Decision Tree | Initial framework |\n",
    "\n",
    "---\n",
    "\n",
    "*This document was generated using the Algorithm Selection Framework notebook.*\n",
    "\"\"\"\n",
    "\n",
    "# Save to file\n",
    "with open(output_path, 'w') as f:\n",
    "    f.write(markdown_content)\n",
    "\n",
    "print(f\"‚úì Framework document exported to: {output_path}\")\n",
    "print(f\"  File size: {len(markdown_content):,} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733d804",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Framework Summary\n",
    "\n",
    "The Algorithm Selection Framework provides a detailed record of the algorithm selection process for building energy clustering. The framework ensures:\n",
    "\n",
    "| Benefit | How Achieved |\n",
    "|---------|--------------|\n",
    "| **Transparency** | All decision factors documented with clear rationale |\n",
    "| **Reproducibility** | Parameters, random seeds, and validation methods specified |\n",
    "| **Stakeholder Trust** | Interpretability requirements explicitly addressed |\n",
    "| **Future Reference** | Exportable document for archiving and sharing |\n",
    "\n",
    "### Key Decision Factors for BDG2 Dataset\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                    ALGORITHM SELECTION SUMMARY                  ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  Data Type:        Mixed (numerical + categorical)              ‚îÇ\n",
    "‚îÇ  Sample Size:      5,902 (medium)                               ‚îÇ\n",
    "‚îÇ  Primary Goal:     Peer group identification                    ‚îÇ\n",
    "‚îÇ  Interpretability: High requirement                             ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  RECOMMENDATION:   K-Prototypes                                 ‚îÇ\n",
    "‚îÇ  Confidence:       High                                         ‚îÇ\n",
    "‚îÇ  Suitability:      9/10                                         ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Preprocessing**: Apply log transformation and RobustScaler to numerical features\n",
    "2. **Missing Data**: Handle 47% missing yearbuilt (imputation or exclusion)\n",
    "3. **Clustering**: Implement K-Prototypes with recommended parameters\n",
    "4. **Validation**: Conduct bootstrap stability assessment (100-200 resamples)\n",
    "5. **Interpretation**: Analyse cluster centroids as building energy benchmarks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
